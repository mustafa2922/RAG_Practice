import streamlit as st
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_groq import ChatGroq
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv
import os

load_dotenv()

# =====================================================
# Page Configuration
st.set_page_config(
    page_title="AI  - Fatwa Assistant",
    page_icon="ğŸ•Œ",
    layout="wide"
)

# =====================================================
# Load vectorstore (cached for performance)
@st.cache_resource
def load_vectorstore():
    """Load the FAISS vectorstore - runs only once"""
    embedding_model = HuggingFaceEmbeddings(model_name="intfloat/multilingual-e5-large")
    vectorstore = FAISS.load_local(
        "../fatwa_index", 
        embedding_model,
        allow_dangerous_deserialization=True
    )
    return vectorstore

@st.cache_resource
def load_llm():
    """Load the LLM - runs only once"""
    # You can also use OpenAI, Anthropic, or any other LLM
    llm = ChatGroq(
        model="openai/gpt-oss-120b",
        temperature=0.1,
        api_key=os.getenv("GROQ_API_KEY")  # Set in environment or Streamlit secrets
    )
    return llm

# =====================================================
# Main UI
st.title("ğŸ•Œ AI  - Islamic Fatwa Assistant")
st.markdown("### Get answers to your Islamic questions based on authentic fatwas")
st.divider()

# Load resources
try:
    with st.spinner("Loading AI  system..."):
        vectorstore = load_vectorstore()
        llm = load_llm()
    st.success("âœ… AI  is ready!")
except Exception as e:
    st.error(f"âŒ Error loading system: {str(e)}")
    st.info("ğŸ’¡ Make sure to set GROQ_API_KEY in your environment or use Streamlit secrets")
    st.stop()

# =====================================================
# Handle example queries from sidebar (must be before text_input)
if 'example_query' in st.session_state:
    default_query = st.session_state.example_query
    del st.session_state.example_query
else:
    default_query = ""

# =====================================================
# Search Interface
col1, col2 = st.columns([3, 1])

with col1:
    query = st.text_input(
        "ğŸ” Ø§Ù¾Ù†Ø§ Ø³ÙˆØ§Ù„ Ù¾ÙˆÚ†Ú¾ÛŒÚº (Ask your question):",
        value=default_query,
        placeholder="e.g., Ù†Ù…Ø§Ø² Ù…ÛŒÚº Ø³ÙˆØ±Û ÙØ§ØªØ­Û Ù¾Ú‘Ú¾Ù†Ø§ Ø¶Ø±ÙˆØ±ÛŒ ÛÛ’ØŸ",
        help="Type your question in Urdu, Arabic, or English",
        key="query_input"
    )

with col2:
    k = st.number_input(
        "ğŸ“Š Fatwas to retrieve:",
        min_value=1,
        max_value=10,
        value=3,
        step=1,
        help="Number of relevant fatwas to use for context"
    )

search_button = st.button("ğŸ¤– Ask AI ", type="primary", use_container_width=True)

# =====================================================
# Custom Prompt Template
prompt_template = """
Ø¢Ù¾ Ø§ÛŒÚ© Ø§Ø³Ù„Ø§Ù…ÛŒ Ø¹Ø§Ù„Ù… Ø§ÙˆØ± Ù…ÙØªÛŒ ÛÛŒÚº Ø¬Ùˆ ØµØ±Ù Ø¯ÛŒÛ’ Ú¯Ø¦Û’ ÙØªØ§ÙˆÛŒ Ú©ÛŒ Ø¨Ù†ÛŒØ§Ø¯ Ù¾Ø± Ø¬ÙˆØ§Ø¨ Ø¯ÛŒØªÛ’ ÛÛŒÚºÛ”

ÙØªØ§ÙˆÛŒ (Context):
{context}

Ø³ÙˆØ§Ù„ (Question): {question}

ÛØ¯Ø§ÛŒØ§Øª (Instructions):
1. ØªÙ…Ø§Ù… ÙØªØ§ÙˆÛŒ Ú©Ùˆ Ø¨ØºÙˆØ± Ù¾Ú‘Ú¾ÛŒÚº Ø§ÙˆØ± Ø§Ù†ÛÛŒ Ú©Û’ Ø§Ù†Ø¯Ø± Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ú©ÛŒ Ø¨Ù†ÛŒØ§Ø¯ Ù¾Ø± Ø¬ÙˆØ§Ø¨ ØªÛŒØ§Ø± Ú©Ø±ÛŒÚºÛ”  
2. Ø¬ÙˆØ§Ø¨ **Ø³Ø§Ø®ØªÛ Ø§Ù†Ø¯Ø§Ø² (structured format)** Ù…ÛŒÚº Ø¯ÛŒÚºØŒ Ø¯Ø±Ø¬ Ø°ÛŒÙ„ Ø­ØµÙˆÚº Ú©Û’ Ø³Ø§ØªÚ¾:
   - **Ø®Ù„Ø§ØµÛ (Summary):** ÙØªØ§ÙˆÛŒ Ú©Û’ Ù…Ø·Ø§Ø¨Ù‚ Ù…Ø®ØªØµØ± Ù†ØªÛŒØ¬ÛÛ”  
   - **ØªÙØµÛŒÙ„ (Explanation):** ÙØªØ§ÙˆÛŒ Ù…ÛŒÚº Ø¨ÛŒØ§Ù† Ú©Ø±Ø¯Û Ø§ØµÙ„ ØªÙØµÛŒÙ„ÛŒ Ø¨Ø§ØªÛ”  
   - **Ø¯Ù„Ø§Ø¦Ù„ ÛŒØ§ Ø­ÙˆØ§Ù„Û’ (References):** ÙˆÛÛŒ Ø¢ÛŒØ§ØªØŒ Ø§Ø­Ø§Ø¯ÛŒØ« ÛŒØ§ ÙÙ‚ÛÛŒ Ù…Ø§Ø®Ø° Ø¬Ùˆ ÙØªØ§ÙˆÛŒ Ù…ÛŒÚº Ø°Ú©Ø± ÛÙˆÚºÛ”  
   - **Ù†ØªÛŒØ¬Û (Conclusion):** ÙØªØ§ÙˆÛŒ Ú©Û’ Ù…Ø·Ø§Ø¨Ù‚ Ø­ØªÙ…ÛŒ Ø­Ú©Ù… ÛŒØ§ ÙÛŒØµÙ„ÛÛ”  
3. ÙØªØ§ÙˆÛŒ Ú©Û’ Ø§Ù„ÙØ§Ø¸ Ú©Ùˆ Ù…Ù…Ú©Ù† Ø­Ø¯ ØªÚ© Ø¨Ø±Ù‚Ø±Ø§Ø± Ø±Ú©Ú¾ÛŒÚºØ› ØµØ±Ù Ù…Ø¹Ù…ÙˆÙ„ÛŒ Ù†Ø­ÙˆÛŒ ØªØ¨Ø¯ÛŒÙ„ÛŒ Ú©Ø±ÛŒÚº Ø§Ú¯Ø± Ø¬Ù…Ù„Û Ù†Ø§Ù‚Øµ ÛÙˆÛ”  
4. Ø§Ù¾Ù†ÛŒ Ø·Ø±Ù Ø³Û’ Ú©ÙˆØ¦ÛŒ Ù†Ø¦ÛŒ Ø¨Ø§ØªØŒ ÙˆØ¶Ø§Ø­ØªØŒ ØªØ´Ø±ÛŒØ­ØŒ ÛŒØ§ Ù…Ø«Ø§Ù„ **Ø´Ø§Ù…Ù„ Ù†Û Ú©Ø±ÛŒÚºÛ”**  
5. Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ Ú©Ø§ Ù…Ú©Ù…Ù„ Ø¬ÙˆØ§Ø¨ ÙØªØ§ÙˆÛŒ Ù…ÛŒÚº Ù†Û ÛÙˆ ØªÙˆ ÙˆØ§Ø¶Ø­ Ø·ÙˆØ± Ù¾Ø± Ù„Ú©Ú¾ÛŒÚº:
   **"Ù…Ø¹Ø°Ø±ØªØŒ Ø§Ø³ Ø³ÙˆØ§Ù„ Ú©Ø§ Ù…Ú©Ù…Ù„ Ø¬ÙˆØ§Ø¨ Ù…ÙˆØ¬ÙˆØ¯Û ÙØªØ§ÙˆÛŒ Ù…ÛŒÚº Ù†ÛÛŒÚº Ù…Ù„Ø§Û”"**  
6. Ø§Ú¯Ø± Ú©Ø³ÛŒ ÙØªÙˆÛ’ Ù…ÛŒÚº ØªØ¶Ø§Ø¯ ÛŒØ§ Ø§Ø®ØªÙ„Ø§Ù ÛÙˆ ØªÙˆ ØµØ±Ù ÙˆÛÛŒ Ù„Ú©Ú¾ÛŒÚº Ø¬Ùˆ ÙØªØ§ÙˆÛŒ Ù…ÛŒÚº Ù…Ø°Ú©ÙˆØ± ÛÛ’Ø› Ø§Ù¾Ù†Ø§ ÙÛŒØµÙ„Û Ù†Û Ø¯ÛŒÚºÛ”  
7. Ø§Ø¯Ø¨ Ø§ÙˆØ± Ø³Ø§Ø¯Ú¯ÛŒ Ú©Û’ Ø³Ø§ØªÚ¾ Ø§Ø±Ø¯Ùˆ Ù…ÛŒÚº Ù„Ú©Ú¾ÛŒÚºÛ”

Ø¬ÙˆØ§Ø¨ (Answer):
"""

PROMPT = PromptTemplate(
    template=prompt_template, 
    input_variables=["context", "question"]
)

# =====================================================
# Search and Get LLM Response
if search_button:
    if not query.strip():
        st.warning("âš ï¸ Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø§Ù¾Ù†Ø§ Ø³ÙˆØ§Ù„ Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚº (Please enter your question)")
    else:
        # Create retriever
        retriever = vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": k}
        )
        
        # Create RAG chain
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True,
            chain_type_kwargs={"prompt": PROMPT}
        )
        
        # Get response
        with st.spinner("ğŸ¤” AI  is thinking..."):
            try:
                result = qa_chain.invoke({"query": query})
                
                # Display AI Response
                st.markdown("## ğŸ¤– AI 's Response")
                st.markdown("---")
                
                # Response in a nice box
                st.markdown(result['result'], unsafe_allow_html=True)
                
                
                st.markdown("---")
                
                # Show retrieved documents for transparency
                st.markdown("## ğŸ“š Source Fatwas Used (For Verification)")
                st.info("ğŸ‘‡ These are the fatwas that were provided to the AI. You can verify the answer against these sources.")
                
                for i, doc in enumerate(result['source_documents'], 1):
                    with st.expander(f"ğŸ“„ Source Fatwa #{i} - {doc.metadata.get('category', 'N/A')}", expanded=False):
                        # Metadata
                        col_a, col_b = st.columns(2)
                        with col_a:
                            st.markdown(f"**ğŸ“ Category:** {doc.metadata.get('category', 'N/A')}")
                        with col_b:
                            url = doc.metadata.get('url', '#')
                            if url != '#':
                                st.markdown(f"**ğŸ”— Source:** [View Original Fatwa]({url})")
                            else:
                                st.markdown(f"**ğŸ”— Source:** N/A")
                        
                        st.divider()
                        
                        # Content
                        st.markdown("**ğŸ“ Full Content:**")
                        st.text_area(
                            label="Content",
                            value=doc.page_content,
                            height=300,
                            key=f"source_content_{i}",
                            label_visibility="collapsed"
                        )
                
            except Exception as e:
                st.error(f"âŒ Error generating response: {str(e)}")
                st.info("ğŸ’¡ Make sure your GROQ_API_KEY is set correctly")

# =====================================================
# Sidebar - Info and Examples
with st.sidebar:
    st.header("â„¹ï¸ About AI ")
    st.markdown("""
    This AI assistant uses:
    - **Retrieval Augmented Generation (RAG)**
    - **Authentic Fatwa Database**
    - **Advanced Language Model**
    
    **How it works:**
    1. Your question is converted to a vector
    2. Most relevant fatwas are retrieved
    3. AI reads these fatwas
    4. AI provides answer based ONLY on these fatwas
    5. Source fatwas are shown for verification
    """)
    
    st.divider()
    
    st.header("âš ï¸ Important Notes")
    st.warning("""
    - AI answers are based on the fatwa database
    - Always verify important matters with qualified scholars
    - Check the source fatwas provided
    - AI may refuse if information is insufficient
    """)
    
    st.divider()
    
    st.header("ğŸ’¡ Example Questions")
    examples = [
        "Ù†Ù…Ø§Ø² Ù…ÛŒÚº Ø³ÙˆØ±Û ÙØ§ØªØ­Û Ù¾Ú‘Ú¾Ù†Ø§ Ø¶Ø±ÙˆØ±ÛŒ ÛÛ’ØŸ",
        "Ø±ÙˆØ²Û’ Ú©ÛŒ Ù†ÛŒØª Ú©Ø¨ ØªÚ© Ú©ÛŒ Ø¬Ø§ Ø³Ú©ØªÛŒ ÛÛ’ØŸ",
        "Ø²Ú©ÙˆÙ°Ûƒ Ú©ÛŒ Ø´Ø±Ø­ Ú©ÛŒØ§ ÛÛ’ØŸ",
        "ÙˆØ¶Ùˆ Ú©Û’ ÙØ±Ø§Ø¦Ø¶ Ú©ÛŒØ§ ÛÛŒÚºØŸ",
        "Ø¬Ù…Ø¹Û Ú©ÛŒ Ù†Ù…Ø§Ø² Ú©ØªÙ†Û’ Ø±Ú©Ø¹Øª ÛÛ’ØŸ"
    ]
    
    for example in examples:
        if st.button(example, use_container_width=True, key=f"example_{example[:10]}"):
            st.session_state.example_query = example
            st.rerun()

# =====================================================
# Footer
st.divider()
st.markdown(
    """
    <div style='text-align: center; color: gray;'>
    ğŸ•Œ AI  System | Powered by RAG, FAISS & LLM<br>
    <small>For educational purposes - Always consult qualified scholars for important matters</small>
    </div>
    """,
    unsafe_allow_html=True
)